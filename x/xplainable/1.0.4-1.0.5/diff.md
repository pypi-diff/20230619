# Comparing `tmp/xplainable-1.0.4-py3-none-any.whl.zip` & `tmp/xplainable-1.0.5-py3-none-any.whl.zip`

## zipinfo {}

```diff
@@ -1,49 +1,49 @@
-Zip file size: 148724 bytes, number of entries: 70
+Zip file size: 150014 bytes, number of entries: 70
 -rw-r--r--  2.0 unx        0 b- defN 23-May-31 05:28 tests/__init__.py
 -rw-r--r--  2.0 unx      488 b- defN 23-Jun-14 12:55 xplainable/__init__.py
--rw-r--r--  2.0 unx       21 b- defN 23-Jun-14 13:02 xplainable/_version.py
+-rw-r--r--  2.0 unx       21 b- defN 23-Jun-19 10:32 xplainable/_version.py
 -rw-r--r--  2.0 unx       27 b- defN 23-May-31 05:28 xplainable/callbacks/__init__.py
 -rw-r--r--  2.0 unx     3705 b- defN 23-Jun-14 12:55 xplainable/callbacks/optimisation.py
 -rw-r--r--  2.0 unx        0 b- defN 23-May-31 05:28 xplainable/client/__init__.py
--rw-r--r--  2.0 unx    23232 b- defN 23-Jun-14 12:55 xplainable/client/client.py
+-rw-r--r--  2.0 unx    24071 b- defN 23-Jun-19 10:32 xplainable/client/client.py
 -rw-r--r--  2.0 unx     3067 b- defN 23-Jun-14 12:55 xplainable/client/init.py
 -rw-r--r--  2.0 unx       21 b- defN 23-May-31 05:28 xplainable/core/__init__.py
 -rw-r--r--  2.0 unx       61 b- defN 23-May-31 05:28 xplainable/core/models.py
 -rw-r--r--  2.0 unx        0 b- defN 23-May-31 05:28 xplainable/core/ml/__init__.py
 -rw-r--r--  2.0 unx    12946 b- defN 23-Jun-14 12:55 xplainable/core/ml/_base_model.py
 -rw-r--r--  2.0 unx    10063 b- defN 23-Jun-14 12:55 xplainable/core/ml/_constructor.py
--rw-r--r--  2.0 unx    25938 b- defN 23-Jun-14 12:55 xplainable/core/ml/classification.py
+-rw-r--r--  2.0 unx    25955 b- defN 23-Jun-19 10:32 xplainable/core/ml/classification.py
 -rw-r--r--  2.0 unx    18856 b- defN 23-Jun-14 12:55 xplainable/core/ml/regression.py
 -rw-r--r--  2.0 unx        0 b- defN 23-May-31 05:28 xplainable/core/nlp/__init__.py
 -rw-r--r--  2.0 unx    22545 b- defN 23-Jun-14 12:55 xplainable/core/nlp/feature_extraction.py
 -rw-r--r--  2.0 unx        0 b- defN 23-May-31 05:28 xplainable/core/optimisation/__init__.py
--rw-r--r--  2.0 unx    14056 b- defN 23-Jun-14 12:55 xplainable/core/optimisation/bayesian.py
+-rw-r--r--  2.0 unx    14737 b- defN 23-Jun-19 10:32 xplainable/core/optimisation/bayesian.py
 -rw-r--r--  2.0 unx     6000 b- defN 23-Jun-14 12:55 xplainable/core/optimisation/genetic.py
--rw-r--r--  2.0 unx    21685 b- defN 23-Jun-14 12:55 xplainable/core/optimisation/layers.py
+-rw-r--r--  2.0 unx    21903 b- defN 23-Jun-19 10:32 xplainable/core/optimisation/layers.py
 -rw-r--r--  2.0 unx     6696 b- defN 23-Jun-14 12:55 xplainable/core/optimisation/nlp.py
 -rw-r--r--  2.0 unx     6906 b- defN 23-Jun-14 12:55 xplainable/core/optimisation/targeting.py
 -rw-r--r--  2.0 unx       22 b- defN 23-May-31 05:28 xplainable/gui/__init__.py
 -rw-r--r--  2.0 unx      112 b- defN 23-May-31 05:28 xplainable/gui/components/__init__.py
 -rw-r--r--  2.0 unx     6347 b- defN 23-Jun-14 12:55 xplainable/gui/components/bars.py
 -rw-r--r--  2.0 unx     4615 b- defN 23-May-31 05:28 xplainable/gui/components/cards.py
 -rw-r--r--  2.0 unx     1093 b- defN 23-May-31 05:28 xplainable/gui/components/connectivity.py
 -rw-r--r--  2.0 unx     3018 b- defN 23-May-31 05:28 xplainable/gui/components/header.py
 -rw-r--r--  2.0 unx     8784 b- defN 23-Jun-14 12:55 xplainable/gui/components/pipelines.py
 -rw-r--r--  2.0 unx     2848 b- defN 23-May-31 05:28 xplainable/gui/components/tables.py
 -rw-r--r--  2.0 unx      100 b- defN 23-May-31 05:28 xplainable/gui/screens/__init__.py
--rw-r--r--  2.0 unx    24051 b- defN 23-Jun-14 12:55 xplainable/gui/screens/classifier.py
+-rw-r--r--  2.0 unx    23982 b- defN 23-Jun-19 10:32 xplainable/gui/screens/classifier.py
 -rw-r--r--  2.0 unx    38580 b- defN 23-Jun-14 12:55 xplainable/gui/screens/evaluate.py
 -rw-r--r--  2.0 unx    14819 b- defN 23-Jun-14 12:55 xplainable/gui/screens/loader.py
 -rw-r--r--  2.0 unx    39855 b- defN 23-Jun-14 12:55 xplainable/gui/screens/preprocessor.py
--rw-r--r--  2.0 unx    19156 b- defN 23-Jun-14 12:55 xplainable/gui/screens/regressor.py
--rw-r--r--  2.0 unx    20243 b- defN 23-Jun-14 12:55 xplainable/gui/screens/save.py
+-rw-r--r--  2.0 unx    19494 b- defN 23-Jun-19 10:32 xplainable/gui/screens/regressor.py
+-rw-r--r--  2.0 unx    20280 b- defN 23-Jun-19 10:32 xplainable/gui/screens/save.py
 -rw-r--r--  2.0 unx    22064 b- defN 23-Jun-14 12:55 xplainable/gui/screens/scenario.py
 -rw-r--r--  2.0 unx       22 b- defN 23-May-31 05:28 xplainable/metrics/__init__.py
--rw-r--r--  2.0 unx     4839 b- defN 23-Jun-14 12:55 xplainable/metrics/metrics.py
+-rw-r--r--  2.0 unx     6074 b- defN 23-Jun-19 10:32 xplainable/metrics/metrics.py
 -rw-r--r--  2.0 unx       27 b- defN 23-May-31 05:28 xplainable/preprocessing/__init__.py
 -rw-r--r--  2.0 unx     6628 b- defN 23-Jun-14 12:55 xplainable/preprocessing/pipeline.py
 -rw-r--r--  2.0 unx       94 b- defN 23-May-31 05:28 xplainable/preprocessing/transformers/__init__.py
 -rw-r--r--  2.0 unx     3518 b- defN 23-Jun-14 12:55 xplainable/preprocessing/transformers/base.py
 -rw-r--r--  2.0 unx    19239 b- defN 23-Jun-14 12:55 xplainable/preprocessing/transformers/categorical.py
 -rw-r--r--  2.0 unx    32659 b- defN 23-Jun-14 12:55 xplainable/preprocessing/transformers/dataset.py
 -rw-r--r--  2.0 unx     3201 b- defN 23-Jun-14 12:55 xplainable/preprocessing/transformers/mixed.py
@@ -60,13 +60,13 @@
 -rw-r--r--  2.0 unx     2111 b- defN 23-May-31 05:28 xplainable/utils/loaders.py
 -rw-r--r--  2.0 unx     1158 b- defN 23-May-31 05:28 xplainable/utils/numba_funcs.py
 -rw-r--r--  2.0 unx     4906 b- defN 23-Jun-14 12:55 xplainable/utils/svgs.py
 -rw-r--r--  2.0 unx     9759 b- defN 23-May-31 05:28 xplainable/utils/xwidgets.py
 -rw-r--r--  2.0 unx        0 b- defN 23-May-31 05:28 xplainable/visualisation/__init__.py
 -rw-r--r--  2.0 unx     4380 b- defN 23-Jun-14 12:55 xplainable/visualisation/explain.py
 -rw-r--r--  2.0 unx      387 b- defN 23-May-31 05:28 xplainable/visualisation/regression.py
--rw-r--r--  2.0 unx    34522 b- defN 23-Jun-14 13:02 xplainable-1.0.4.dist-info/LICENSE
--rw-r--r--  2.0 unx    48276 b- defN 23-Jun-14 13:02 xplainable-1.0.4.dist-info/METADATA
--rw-r--r--  2.0 unx       92 b- defN 23-Jun-14 13:02 xplainable-1.0.4.dist-info/WHEEL
--rw-r--r--  2.0 unx       17 b- defN 23-Jun-14 13:02 xplainable-1.0.4.dist-info/top_level.txt
-?rw-rw-r--  2.0 unx     6260 b- defN 23-Jun-14 13:02 xplainable-1.0.4.dist-info/RECORD
-70 files, 586131 bytes uncompressed, 138676 bytes compressed:  76.3%
+-rw-r--r--  2.0 unx    34522 b- defN 23-Jun-19 10:32 xplainable-1.0.5.dist-info/LICENSE
+-rw-r--r--  2.0 unx    50058 b- defN 23-Jun-19 10:32 xplainable-1.0.5.dist-info/METADATA
+-rw-r--r--  2.0 unx       92 b- defN 23-Jun-19 10:32 xplainable-1.0.5.dist-info/WHEEL
+-rw-r--r--  2.0 unx       17 b- defN 23-Jun-19 10:32 xplainable-1.0.5.dist-info/top_level.txt
+?rw-rw-r--  2.0 unx     6260 b- defN 23-Jun-19 10:32 xplainable-1.0.5.dist-info/RECORD
+70 files, 591209 bytes uncompressed, 139966 bytes compressed:  76.3%
```

## zipnote {}

```diff
@@ -189,23 +189,23 @@
 
 Filename: xplainable/visualisation/explain.py
 Comment: 
 
 Filename: xplainable/visualisation/regression.py
 Comment: 
 
-Filename: xplainable-1.0.4.dist-info/LICENSE
+Filename: xplainable-1.0.5.dist-info/LICENSE
 Comment: 
 
-Filename: xplainable-1.0.4.dist-info/METADATA
+Filename: xplainable-1.0.5.dist-info/METADATA
 Comment: 
 
-Filename: xplainable-1.0.4.dist-info/WHEEL
+Filename: xplainable-1.0.5.dist-info/WHEEL
 Comment: 
 
-Filename: xplainable-1.0.4.dist-info/top_level.txt
+Filename: xplainable-1.0.5.dist-info/top_level.txt
 Comment: 
 
-Filename: xplainable-1.0.4.dist-info/RECORD
+Filename: xplainable-1.0.5.dist-info/RECORD
 Comment: 
 
 Zip file comment:
```

## xplainable/_version.py

```diff
@@ -1 +1 @@
-__version__ = "1.0.4"
+__version__ = "1.0.5"
```

## xplainable/client/client.py

```diff
@@ -6,14 +6,15 @@
 from requests.adapters import HTTPAdapter
 from requests.packages.urllib3.util.retry import Retry
 from ..gui.screens.preprocessor import Preprocessor
 from ..preprocessing import transformers as xtf
 from ..utils.exceptions import AuthenticationError
 from ..gui.components.cards import render_user_avatar
 from ..quality.scanner import XScan
+from ..metrics.metrics import evaluate_classification, evaluate_regression
 from ..core.models import (XClassifier, XRegressor, PartitionedRegressor,
                            PartitionedClassifier)
 
 import json
 import numpy as np
 import pandas as pd
 import pyperclip
@@ -405,15 +406,15 @@
         else:
             raise ValueError(
                 f'Model type {cls_name} is not supported')
         
         return model_type, model.target
 
     def create_model_id(
-            self, model_name: str, model_description: str, model) -> str:
+            self, model, model_name: str, model_description: str) -> str:
         """ Creates a new model and returns the model id.
 
         Args:
             model_name (str): The name of the model
             model_description (str): The description of the model
             model (XClassifier | XRegressor): The model to create.
 
@@ -423,28 +424,29 @@
 
         model_type, target = self._detect_model_type(model)
 
         payoad = {
             "model_name": model_name,
             "model_description": model_description,
             "model_type": model_type,
-            "target_name": target
+            "target_name": target,
+            "algorithm": model.__class__.__name__
         }
         
         response = self.__session__.post(
             url=f'{self.hostname}/v1/{self.__ext}/create-model',
             json=payoad
         )
         
         model_id = get_response_content(response)
             
         return model_id
 
     def create_model_version(
-            self, model, model_id: str, df: pd.DataFrame = None) -> str:
+            self, model, model_id: str, x: pd.DataFrame, y: pd.Series) -> str:
         """ Creates a new model version and returns the version id.
 
         Args:
             model_id (int): The model id
             partition_on (str): The partition column name
             ruleset (dict | str): The feeature ruleset
             health_info (dict): Feature health information
@@ -477,38 +479,40 @@
 
         partitioned_models = ['PartitionedClassifier', 'PartitionedRegressor']
         independent_models = ['XClassifier', 'XRegressor']
 
         # get all partitions
         if model.__class__.__name__ in partitioned_models:
             for p, m in model.partitions.items():
-                part = None
-                if df is not None:
-                    if p == '__dataset__':
-                        part = df
-                    else:
-                        part = df[df[partition_on] == p]
+                if p == '__dataset__':
+                    part_x = x
+                    part_y = y
+
+                else:
+                    part_x = x[x[partition_on].astype(str) == str(p)]
+                    part_y = y[y.index.isin(part_x.index)]
 
-                pdata = self._get_partition_data(m, p, part)
+                pdata = self._get_partition_data(m, p, part_x, part_y)
                 payload['partitions'].append(pdata)
         
         elif model.__class__.__name__ in independent_models:
-            pdata = self._get_partition_data(model, '__dataset__', df)
+            pdata = self._get_partition_data(model, '__dataset__', x, y)
             payload['partitions'].append(pdata)
 
         # Create a new version and fetch id
         url = f'{self.hostname}/v1/{self.__ext}/models/{model_id}/add-version'
         response = self.__session__.post(url=url,json=payload)
 
         version_id = get_response_content(response)
 
         return version_id
 
     def _get_partition_data(
-            self, model, partition_name: str, df: pd.DataFrame = None):
+            self, model, partition_name: str, x: pd.DataFrame,
+            y: pd.Series) -> dict:
         """ Logs a partition to a model version.
 
         Args:
             model_type (str): The model type
             partition_name (str): The name of the partition column
             model (mixed): The model to log
             model_id (int): The model id
@@ -547,25 +551,43 @@
             data.update({
                 "calibration_map": json.loads(
                     json.dumps(model._calibration_map, cls=NpEncoder)),
                 "support_map": json.loads(
                 json.dumps(model._support_map, cls=NpEncoder))
             })
 
-        data["evaluation"] = json.dumps(
-            model.metadata.get('evaluation', {}), cls=NpEncoder)
+            evaluation = model.metadata.get('evaluation', {})
+            if evaluation == {}:
+                y_prob = model.predict_score(x)
+
+                if model.target_map:
+                    y = y.map(model.target_map)
+
+                evaluation = {
+                            'train': evaluate_classification(y, y_prob)
+                        }
+                
+        elif model_type == 'regression':
+            evaluation = model.metadata.get('evaluation', {})
+            if evaluation == {}:
+                y_pred = model.predict(x)
+                evaluation = {
+                            'train': evaluate_regression(y, y_pred)
+                        }
+
+        data["evaluation"] = json.dumps(evaluation, cls=NpEncoder)
 
         training_metadata = {
             i: v for i, v in model.metadata.items() if i != "evaluation"}
         
         data["training_metadata"] = json.dumps(training_metadata, cls=NpEncoder)
         
-        if df is not None:
+        if x is not None:
             scanner = XScan()
-            scanner.scan(df)
+            scanner.scan(x)
 
             results = []
             for i, v in scanner.profile.items():
                 feature_info = {
                     "feature": i,
                     "description": '',
                     "type": v['type'],
@@ -574,16 +596,16 @@
                 results.append(feature_info)
 
             data["health_info"] = json.dumps(results, cls=NpEncoder)
 
         return data
 
     def deploy(
-            self, hostname: None, model_id: str, version_id: str, partition_id: str,
-            raw_output: bool=False) -> dict:
+            self, hostname: None, model_id: str, version_id: str,
+            partition_id: str, raw_output: bool=False) -> dict:
         """ Deploys a model partition to xplainable cloud.
 
         The hostname should be the url of the inference server. For example:
         https://inference.xplainable.io
 
         Args:
             hostname (str): The host name for the inference server
```

## xplainable/core/ml/classification.py

```diff
@@ -528,15 +528,15 @@
         y_pred = (y_prob > threshold).astype(int)
 
         if (len(self.target_map) > 0) and (y.dtype == 'object'):
             y = y.copy().map(self.target_map)
 
         # Calculate metrics
         cm = confusion_matrix(y, y_pred).tolist()
-        cr = classification_report(y, y_pred, output_dict=True)
+        cr = classification_report(y, y_pred, output_dict=True, zero_division=0)
 
         try:
             roc_auc = roc_auc_score(y, y_prob)
         except Exception:
             roc_auc = np.nan
 
         try:
```

## xplainable/core/optimisation/bayesian.py

```diff
@@ -143,56 +143,67 @@
             else:
                 y_pred = model.predict(X_.loc[test_index], remap=False)
 
             y_test = y_.loc[test_index]
 
             # Calculate the score for the fold
             if self.metric == 'macro-f1':
-                scores.append(skm.f1_score(y_test, y_pred, average='macro'))
+                scores.append(skm.f1_score(y_test, y_pred, average='macro',
+                                           zero_division=0))
 
             elif self.metric == 'weighted-f1':
-                scores.append(skm.f1_score(y_test, y_pred, average='weighted'))
+                scores.append(skm.f1_score(y_test, y_pred, average='weighted',
+                                           zero_division=0))
 
             elif self.metric == 'positive-f1':
-                scores.append(skm.f1_score(y_test, y_pred, average=None)[1])
+                scores.append(skm.f1_score(y_test, y_pred, average=None,
+                                           zero_division=0)[1])
 
             elif self.metric == 'negative-f1':
-                scores.append(skm.f1_score(y_test, y_pred, average=None)[0])
+                scores.append(skm.f1_score(y_test, y_pred, average=None,
+                                           zero_division=0)[0])
 
             elif self.metric == 'macro-precision':
                 scores.append(
-                    skm.precision_score(y_test, y_pred, average='macro'))
+                    skm.precision_score(y_test, y_pred, average='macro',
+                                        zero_division=0))
 
             elif self.metric == 'weighted-precision':
                 scores.append(
-                    skm.precision_score(y_test, y_pred, average='weighted'))
+                    skm.precision_score(y_test, y_pred, average='weighted',
+                                        zero_division=0))
 
             elif self.metric == 'positive-precision':
                 scores.append(
-                    skm.precision_score(y_test, y_pred, average=None)[1])
+                    skm.precision_score(y_test, y_pred, average=None,
+                                        zero_division=0)[1])
 
             elif self.metric == 'negative-precision':
                 scores.append(
-                    skm.precision_score(y_test, y_pred, average=None)[0])
+                    skm.precision_score(y_test, y_pred, average=None,
+                                        zero_division=0)[0])
 
             elif self.metric == 'macro-recall':
                 scores.append(
-                    skm.precision_score(y_test, y_pred, average='macro'))
+                    skm.recall_score(y_test, y_pred, average='macro',
+                                        zero_division=0))
 
             elif self.metric == 'weighted-recall':
                 scores.append(
-                    skm.precision_score(y_test, y_pred, average='weighted'))
+                    skm.recall_score(y_test, y_pred, average='weighted'))
 
             elif self.metric == 'positive-recall':
                 scores.append(
-                    skm.precision_score(y_test, y_pred, average=None)[1])
+                    skm.recall_score(y_test, y_pred, average=None,
+                                     zero_division=0)[1])
 
             elif self.metric == 'negative-recall':
                 scores.append(
-                    skm.precision_score(y_test, y_pred, average=None)[0])
+                    skm.recall_score(y_test, y_pred, average=None,
+                                     zero_division=0)[0])
 
             elif self.metric == 'accuracy':
                 scores.append(skm.accuracy_score(y_test, y_pred))
 
             elif self.metric == 'brier-loss':
                 # Negative as we want to minimise the score
                 scores.append(1 - skm.brier_score_loss(y_test, y_prob))
@@ -205,15 +216,16 @@
                 try:
                     scores.append(skm.roc_auc_score(y_test, y_prob))
                 except Exception as e:
                     scores.append(np.nan)
                     _has_nan = True
 
             else:
-                scores.append(skm.f1_score(y_test, y_pred, average='weighted'))
+                scores.append(skm.f1_score(y_test, y_pred, average='weighted',
+                                           zero_division=0))
 
             if self.callback:
                 # fold callback
                 self.callback.fold(i+1)
 
         score = np.nanmean(scores) if _has_nan else np.mean(scores)
```

## xplainable/core/optimisation/layers.py

```diff
@@ -2,14 +2,15 @@
 
 import numpy as np
 import random
 import math
 from numba import njit, prange
 from ...utils.numba_funcs import *
 from .genetic import XEvolutionaryNetwork
+import warnings
 
 
 class BaseLayer:
     """ Base class for optimisation layers.
 
     Args:
         metric (str, optional): Metric to optimise on. Defaults to 'mae'.
@@ -571,28 +572,32 @@
         u_vals = (errmp * u_mask)
         u_vals[u_vals == 0] = np.nan
 
         if self.metric == 'mse':
             o_vals = o_vals**2
             u_vals = u_vals**2
 
-        # get mean error and count of obs that are too high for each leaf
-        om = np.nanmean(o_vals, axis=0)
-        oc = o_mask.sum(axis=0)
-
-         # get mean error and count of obs that are too low for each leaf
-        um = np.nanmean(abs(u_vals), axis=0)
-        uc = u_mask.sum(axis=0)
+        # surpress know warning that raises when all values are nan
+        with warnings.catch_warnings():
+            warnings.simplefilter("ignore", category=RuntimeWarning)
+
+            # get mean error and count of obs that are too high for each leaf
+            om = np.nanmean(o_vals, axis=0)
+            oc = o_mask.sum(axis=0)
+
+            # get mean error and count of obs that are too low for each leaf
+            um = np.nanmean(abs(u_vals), axis=0)
+            uc = u_mask.sum(axis=0)
 
         # calculate max benefit of inc/dec each leaf
         inc = (um * uc) - (um * oc) - (um * ec)
         dec = (om * oc) - (om * uc) - (om * ec)
 
         # get the best outcomes
-        bsts = np.maximum(inc, dec)
+        bsts = np.nanmax([inc, dec])
 
         # find individual best outcome and loc
         bst = np.nanmax(bsts)
         bstloc = np.where(bsts==bst)[0][0]
 
         # get value to update by
         if inc[bstloc] > dec[bstloc]:
```

## xplainable/gui/screens/classifier.py

```diff
@@ -563,35 +563,35 @@
             #outt.layout.display = 'flex'
 
             eval_screens = {}
 
             if optimise.value:
                 _max_depth_space = list(max_depth_space.value) + \
                     [max_depth_step.value]
-                _max_depth_space[1] += _max_depth_space[2]
+                _max_depth_space[1] += 0.0001
                 
                 _min_leaf_size_space = list(min_leaf_size_space.value) + \
                     [min_leaf_size_step.value]
-                _min_leaf_size_space[1] += _min_leaf_size_space[2]
+                _min_leaf_size_space[1] += 0.0001
 
                 _min_info_gain_space = list(min_info_gain_space.value) + \
                     [min_info_gain_step.value]
-                _min_info_gain_space[1] += _min_info_gain_space[2]
+                _min_info_gain_space[1] += 0.0001
 
                 _weight_space = list(weight_space.value) + \
                     [weight_step.value]
-                _weight_space[1] += _weight_space[2]
+                _weight_space[1] += 0.0001
 
                 _power_degree_space = list(power_degree_space.value) + \
                     [power_degree_step.value]
-                _power_degree_space[1] += _power_degree_space[2]
+                _power_degree_space[1] += 0.0001
 
                 _sigmoid_exponent_space = list(sigmoid_exponent_space.value) + \
                     [sigmoid_exponent_step.value]
-                _sigmoid_exponent_space[1] += _sigmoid_exponent_space[2]
+                _sigmoid_exponent_space[1] += 0.0001
 
                 callback, opt_bars_display, param_bars_display = generate_callback(
                 _max_depth_space, _min_leaf_size_space, _min_info_gain_space,
                 _weight_space, _power_degree_space, _sigmoid_exponent_space
                 )
 
                 desc_partition = widgets.HTML(f'<strong>Partition: </strong>-')
@@ -625,16 +625,15 @@
 
                 try:
                     if optimise.value:
                         desc_partition.value = f'<strong>Partition: </strong>{p}'
                         callback.reset()
                         
                     if p != '__dataset__':
-                        part = df[df[partition_on.value] == p].drop(
-                            columns=[partition_on.value])
+                        part = df[df[partition_on.value] == p]
         
                         if len(part) < 100:
                             continue
 
                         X, y = part.drop(columns=[target.value]), part[target.value]
                         X_train, X_test, y_train, y_test = train_test_split(
                             X, y, test_size=validation_size.value,
@@ -711,15 +710,17 @@
                 callback.finalise()
                 opt_display.close()
             
             part_progress.collapse_items(items=['Partitions'])
             header.title = {'title': 'Profile'}
             divider.close()
 
-            save = ModelPersist(partitioned_model, 'binary_classification', df)
+            X, y = df.drop(columns=[target.value]), df[target.value]
+            save = ModelPersist(
+                partitioned_model, 'binary_classification', X, y)
 
             partition_select = widgets.Dropdown(
                 options = eval_screens.keys()
             )
 
             partition_select.layout = widgets.Layout(margin='10px 0 0 0')
```

## xplainable/gui/screens/regressor.py

```diff
@@ -387,46 +387,45 @@
             model.max_depth = _slider_max_depth.value
             model.min_leaf_size = _slider_min_leaf_size.value
             model.min_info_gain = _slider_min_info_gain.value
             model.tail_sensitivity = _slider_tail_sensitivity.value
             model.alpha = _slider_alpha.value
             
             if p != '__dataset__':
-                part = df[df[p_on] == p].drop(columns=[p_on])
+                part = df[df[p_on] == p]
 
                 if len(part) < 100:
                     continue
 
                 X = part.drop(columns=[_dropdown_target.value])
                 y = part[_dropdown_target.value]
 
                 X_train, X_test, y_train, y_test = train_test_split(
                     X, y, test_size=_slider_validation_size.value,
                     random_state=1)
                 
             else:
                 drop_cols = [_dropdown_target.value]
-
                 if _dropdown_partition_on.value is not None:
-                    drop_cols.append(p_on)
+                            drop_cols.append(_dropdown_partition_on.value)
 
                 X, y = df.drop(columns=drop_cols), df[_dropdown_target.value]
                 X_train, X_test, y_train, y_test = train_test_split(
                     X, y, test_size=_slider_validation_size.value,
                     random_state=1)
             
             id_cols = [
                 i for i in list(_selector_id_columns.value) if i is not None]
             
             kvt.update_data({
                 'status': 'fitting model',
                 'partition': p,
                 'layers': f'{len(xnet.future_layers)}'
             })
-            
+
             start = time.time()
             model.fit(X_train, y_train, id_columns=id_cols)
             
             model.metadata['optimisation'] = {}
             
             if _toggle_optimise_ts.value:
                 kvt.update_data({
@@ -453,15 +452,20 @@
 
                     X_train = X_train.sample(
                         int(len(X_train) * _slider_opt_sample.value))
                     
                     y_train = y_train.loc[X_train.index]
                 
                 start = time.time()
-                network.fit(X_train, y_train)
+                if _dropdown_partition_on.value is not None:
+                    network.fit(
+                        X_train.drop(columns=[_dropdown_partition_on.value]),
+                        y_train)
+                else:
+                    network.fit(X_train, y_train)
                 
                 output_screen.children = (output_screen.children[0],) + \
                     (callback.group.show(),)
                 
                 network.optimise(callback=callback)
 
                 elapsed = round(time.time()-start, 4)
@@ -486,15 +490,18 @@
             model.metadata['evaluation'] = eval_items
             part_progress.set_value('Partitions', i)
             
         part_progress.collapse_items(items=['Partitions'])
         divider.close()
         header.title = {'title': 'Profile'}
         
-        save = ModelPersist(partitioned_model, 'regression', df)
+        X, y = df.drop(
+            columns=[_dropdown_target.value]), df[_dropdown_target.value]
+        
+        save = ModelPersist(partitioned_model, 'regression', X, y)
         
         partition_select = widgets.Dropdown(
             options = eval_screens.keys()
         )
 
         partition_select.layout = widgets.Layout(margin='10px 0 0 0')
```

## xplainable/gui/screens/save.py

```diff
@@ -14,21 +14,22 @@
 from xplainable.utils.xwidgets import TextInput
 
 import time
 
 
 class ModelPersist:
     
-    def __init__(self, model, model_type, df=None):
+    def __init__(self, model, model_type, X, y):
 
         self.model = model
         self.model_type = model_type
         self.partition_on = model.partition_on
         self.partitions = list(self.model.partitions.keys())
-        self.df = df
+        self.X = X
+        self.y = y
         self.selected_model_id = None
 
     def save(self):
 
         model_name = TextInput(
             label="Name: ",
             label_type='h5',
@@ -179,30 +180,31 @@
             confirm_button.description = "Saving..."
             confirm_button.disabled = True
             loading.max = 2
             loading.layout.display = 'flex'
             
             if buttons.index == 0:
                 model_id = xplainable.client.create_model_id(
+                    self.model,
                     model_name.value,
-                    model_description.value,
-                    self.model
+                    model_description.value
                 )
 
             else:
                 model_id = self.selected_model_id
             
             loading.value = loading.value + 1
 
             loading_status.value = f'Creating model version...'
             
             version_id = xplainable.client.create_model_version(
                 self.model,
                 model_id,
-                self.df
+                self.X,
+                self.y
                 )
             
             loading.value = loading.value + 1
             
             loading_status.value = ''
             loading.layout.display = 'none'
             loading.value = 0
```

## xplainable/metrics/metrics.py

```diff
@@ -36,14 +36,56 @@
         output_data.append({
             "class": cls,
             "values": list(counts)
         })
     
     return output_data
 
+def calculate_regression_bins(y_true, y_pred, bin_count):
+
+    # Ensure y_true and y_pred are NumPy arrays
+    y_true = np.array(y_true)
+    y_pred = np.array(y_pred)
+
+    # Calculate the min and max of the predicted values
+    min_val = min(y_pred)
+    max_val = max(y_pred)
+
+    # Define the bins
+    bins = np.linspace(min_val, max_val, bin_count+1)
+
+    # Assign each predicted value to a bin
+    true_bin_indices = np.digitize(y_true, bins)
+    pred_bin_indices = np.digitize(y_pred, bins)
+
+    # For each bin, count the number of true values
+    true_output = []
+    pred_output = []
+    for i in range(1, bin_count+1):
+        true_values_in_bin = y_true[true_bin_indices == i]
+        true_counts = len(true_values_in_bin)
+        true_output.append(true_counts)
+        
+        pred_values_in_bin = y_pred[pred_bin_indices == i]
+        pred_counts = len(pred_values_in_bin)
+        pred_output.append(pred_counts)
+    
+    output = [
+        {
+            "class": "true",
+            "values": true_output
+        },
+        {
+            "class": "pred",
+            "values": pred_output
+        }
+    ]
+    
+    return output
+
 def evaluate_classification(y_true, y_pred):
     results = {}
     thresholds = np.linspace(0, 1, 101)
     
     # TP, FP, TN, FN at each threshold value
     metrics = []
     for threshold in thresholds:
@@ -96,16 +138,16 @@
     results["probability_bins"] = calculate_probability_bins(y_true, y_pred)
 
     return force_json_compliant(results)
 
 def evaluate_regression(y_true, y_pred):
     results = {
         "charts": {
-            'true': y_true.values if len(y_true) < 10000 else y_true[:10000].values,
-            'prediction': y_pred if len(y_pred) < 10000 else y_pred[:10000],
+            'true': list(y_true.values if len(y_true) < 10000 else y_true[:10000].values),
+            'prediction': list(y_pred if len(y_pred) < 10000 else y_pred[:10000]),
         }
     }
     
     # Mean Absolute Error (MAE)
     try:
         results["mae"] = mean_absolute_error(y_true, y_pred)
     except:
@@ -149,9 +191,11 @@
         results["rmsle"] = np.nan
     
     # Mean Absolute Percentage Error (MAPE)
     try:
         results["mape"] = mean_absolute_percentage_error(y_true, y_pred)
     except:
         results["mape"] = np.nan
+
+    results["prediction_bins"] = calculate_regression_bins(y_true, y_pred, 100)
     
     return force_json_compliant(results)
```

## Comparing `xplainable-1.0.4.dist-info/LICENSE` & `xplainable-1.0.5.dist-info/LICENSE`

 * *Files identical despite different names*

## Comparing `xplainable-1.0.4.dist-info/METADATA` & `xplainable-1.0.5.dist-info/METADATA`

 * *Files 5% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 Metadata-Version: 2.1
 Name: xplainable
-Version: 1.0.4
+Version: 1.0.5
 Summary: Real-time explainable machine learning for business optimisation
 Author: xplainable pty ltd
 Author-email: xplainable pty ltd <contact@xplainable.io>
 License: GNU AFFERO GENERAL PUBLIC LICENSE
                                Version 3, 19 November 2007
         
          Copyright (C) 2007 Free Software Foundation, Inc. <https://fsf.org/>
@@ -702,15 +702,15 @@
 <div align="center">
 <img src="https://raw.githubusercontent.com/xplainable/xplainable/main/docs/assets/logo/xplainable-logo.png">
 <h1 align="center">xplainable</h1>
 <h3 align="center">Real-time explainable machine learning for business optimisation</h3>
     
 [![Python](https://img.shields.io/pypi/pyversions/xplainable)](https://pypi.org/project/xplainable/)
 [![PyPi](https://img.shields.io/pypi/v/xplainable?color=blue)](https://pypi.org/project/xplainable/)
-[![License: AGPL v3](https://img.shields.io/badge/License-AGPL_v3-blue.svg)](https://github.com/xplainable/xplainable/blob/dev/LICENSE)
+[![License: AGPL v3](https://img.shields.io/badge/License-AGPL_v3-blue.svg)](https://github.com/xplainable/xplainable/blob/main/LICENSE)
 [![Downloads](https://static.pepy.tech/badge/xplainable)](https://pepy.tech/project/xplainable)
     
 **Xplainable** leverages explainable machine learning for fully transparent predictions and advanced data optimisation in production systems.
 </div>
 
 
 ## Installation
@@ -783,26 +783,57 @@
 |:------|:------:|:------:|
 | Data Health Checks | ✅ | ✅ |
 | Transformers Library | ✅ | ✅ |
 | Preprocessing Pipelines | ✅ | ✅ |
 | Pipeline Persistance | ✅ | ✅ |
 </div>
 
+#### Using the GUI
+
 ```python
 pp = xp.Preprocessor()
 
 pp.preprocess(train)
 ```
 <div align="center">
 
 <img src="https://raw.githubusercontent.com/xplainable/xplainable/main/docs/assets/gifs/preprocessing.gif">
 
 </div><br>
 
+#### Using the API
+```python
+from xplainable.preprocessing.pipeline import XPipeline
+from xplainable.preprocessing import transformers as xtf
+
+pipeline = XPipeline()
+
+# Add stages for specific features
+pipeline.add_stages([
+    {"feature": "age", "transformer": xtf.Clip(lower=18, upper=99)},
+    {"feature": "balance", "transformer": xtf.LogTransform()}
+])
+
+# add stages on multiple features
+pipeline.add_stages([
+    {"transformer": xtf.FillMissing({'job': 'mode', 'age': 'mean'})},
+    {"transformer": xtf.DropCols(columns=['duration', 'campaign'])}
+])
+
+# Fit and transform the data
+train_transformed = pipeline.fit_transform(train)
+
+# Apply transformations on new data
+test_transformed = pipeline.transform(test)
+
+```
+
+
 ### Modelling
+
 Xplainable models can be developed, optimised, and re-optimised using Pythonic
 APIs or the embedded GUI.
 
 <div align="center">
 
 | Feature | Python API| Jupyter GUI |
 |:------|:------:|:------:|
@@ -811,29 +842,74 @@
 | Hyperparameter Optimisation | ✅ | ✅ |
 | Partitioned Models | ✅ | ✅ |
 | **Rapid Refitting** (novel to xplainable) | ✅ | ✅ |
 | Model Persistance | ✅ | ✅ |
 
 </div>
 
+#### Using the GUI
+
 ```python
 model = xp.classifier(train)
 ```
 <div align="center">
 <img src="https://raw.githubusercontent.com/xplainable/xplainable/main/docs/assets/gifs/gui_classifier.gif">
 </div><br>
 
+#### Using the API
+```python
+from xplainable.core.models import XClassifier
+from xplainable.core.optimisation.bayesian import XParamOptimiser
+from sklearn.model_selection import train_test_split
+import pandas as pd
+
+# Load your data
+data = pd.read_csv('data.csv')
+x, y = data.drop('target', axis=1), data['target']
+X_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2)
+
+# Optimise params
+opt = XParamOptimiser(metric='roc-auc')
+params = opt.optimise(X_train, y_train)
+
+# Train your model
+model = XClassifier(**params)
+model.fit(X_train, y_train)
+
+# Predict on the test set
+y_pred = model.predict(x_test)
+```
+
+#### Using the GUI
+
 ### Rapid Refitting
 Fine tune your models by refitting model parameters on the fly, even on
 individual features.
 
 <div align="center">
 <img src="https://raw.githubusercontent.com/xplainable/xplainable/main/docs/assets/gifs/recalibrate.gif">
 </div><br>
 
+#### Using the API
+```python
+new_params = {
+            "features": ['Age'],
+            "max_depth": 6,
+            "min_info_gain": 0.01,
+            "min_leaf_size": 0.03,
+            "weight": 0.05,
+            "power_degree": 1,
+            "sigmoid_exponent": 1,
+            "x": X_train,
+            "y": y_train
+}
+
+model.update_feature_params(**new_params)
+```
+
 ### Explainability
 Models are explainable and real-time, right out of the box, without having to fit
 surrogate models such as [Shap](https://github.com/slundberg/shap) or[Lime](https://github.com/marcotcr/lime).
 
 <div align="center">
 
 | Feature | Python API| Jupyter GUI |
@@ -916,16 +992,14 @@
 ## Contributors
 We'd love to welcome contributors to xplainable to keep driving forward more
 transparent and actionable machine learning. We're working on our contributor
 docs at the moment, but if you're interested in contributing, please send us a
 message at contact@xplainable.io.
 
 
-
-
 <div align="center">
 <br></br>
 <br></br>
 Thanks for trying xplainable!
 <br></br>
 <strong>Made with ❤️ in Australia</strong>
 <br></br>
```

## Comparing `xplainable-1.0.4.dist-info/RECORD` & `xplainable-1.0.5.dist-info/RECORD`

 * *Files 6% similar despite different names*

```diff
@@ -1,48 +1,48 @@
 tests/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 xplainable/__init__.py,sha256=7MV0oMkcwb1OrCv_I7IrrFdK-Nv9DAQ8Fh0pHytAbxQ,488
-xplainable/_version.py,sha256=O-a1T6uLdX0DYXelAnzqY4NDGktopbWdpKZloec7oxY,21
+xplainable/_version.py,sha256=ZR1VA9cGs0vIK6cWK4YKLfBTnmUCAcDaaP9ARPPYxEs,21
 xplainable/callbacks/__init__.py,sha256=0RRftTFsiuCCp8mBluQS_0_uqwoKqABPW6PP__yNtwg,27
 xplainable/callbacks/optimisation.py,sha256=JQm8xbfR5BFMQZKObsOA12VKmDHJ7xeaDjlYd66s2Ik,3705
 xplainable/client/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
-xplainable/client/client.py,sha256=JN0l1qT2eGsbs-1K_2jm_PnmjqzXafMU4p8nxoak_Zo,23232
+xplainable/client/client.py,sha256=wP904H_NbYwtVcpUx4Q8ItfLxIpNkAoKDVU8B1mb3dg,24071
 xplainable/client/init.py,sha256=iis82asRx6qiJ4DcquadxIv1_NsWMdZcNDreNzrtf5w,3067
 xplainable/core/__init__.py,sha256=SRfF7oDVlOOAi6nGKiJIUK6B_arqYLO9iSMp-2IZZps,21
 xplainable/core/models.py,sha256=EwqOcETvdimcJGlMhku3qfK00NmyuMC4Qk3yQajQHnk,61
 xplainable/core/ml/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 xplainable/core/ml/_base_model.py,sha256=T8jo0m2w_K2wR4UW825uUEfrG9ufJ9a0n0iqkiG1CMk,12946
 xplainable/core/ml/_constructor.py,sha256=EnNwfKJEk_wy-VIETkdtFPoUA9SHZgK9IxezCQYCM5o,10063
-xplainable/core/ml/classification.py,sha256=Tw4ABXb5t1cgDHlPGVz0CU0iyjYGG2t3oyuYGEzzlHI,25938
+xplainable/core/ml/classification.py,sha256=keSf9SsU2vexRexJKfNN4Z4p8Y14uMJW3MgoMzzON0Y,25955
 xplainable/core/ml/regression.py,sha256=qSMf7QisXJcJIArkKkYkVJpVWEKo3H5lvXumSenmU2A,18856
 xplainable/core/nlp/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 xplainable/core/nlp/feature_extraction.py,sha256=MqLh5o1JYyg0SJQga921QuGriXufdWENxSOWcnlsNkc,22545
 xplainable/core/optimisation/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
-xplainable/core/optimisation/bayesian.py,sha256=M1XdzUYOYQWtjHWU8TUiD8kOAa2-7hYhW6JmhGj1JFg,14056
+xplainable/core/optimisation/bayesian.py,sha256=k1dWm9HgLY_m_KXq_uNwMgDRKsRNgePITraqMFV2lbY,14737
 xplainable/core/optimisation/genetic.py,sha256=mkQ9czuZKTXP3NN5n59kcYn3BJPkEmfu-tcnTOHMatU,6000
-xplainable/core/optimisation/layers.py,sha256=aAL30s9l7xYoki-re-ae3h-YEDJ7IEoahS8rw92jbFs,21685
+xplainable/core/optimisation/layers.py,sha256=gX2UBW86axjHP5i_6Jejw7ZkziK11a_xTXrgSNqrYoU,21903
 xplainable/core/optimisation/nlp.py,sha256=kPzQ6_WqtYO38jA8Im4OGFTUxjpW7idBU5OK6YRadg0,6696
 xplainable/core/optimisation/targeting.py,sha256=Mrl7LlvS_3D4Rcq84bd9MH05Ic9i9gDPN3__yzykN1c,6906
 xplainable/gui/__init__.py,sha256=WBrwfbSHJCEQVMxZcFFJGFt1NCSEtGRVxKDT6Q0k72g,22
 xplainable/gui/components/__init__.py,sha256=90-xUw4GbPXPnJs939DqWsZ8IBaKLlc2Z7szgoSPuUw,112
 xplainable/gui/components/bars.py,sha256=vxgxyqOYIvkokAKxrGDxgTZd7_ZodULoP4aTmvaVahQ,6347
 xplainable/gui/components/cards.py,sha256=1luOzr6Z_zRxoVU1Xr1kskVeolhZ7709Dr_RzuCpUPI,4615
 xplainable/gui/components/connectivity.py,sha256=CwlyGH8tnrU0_5tPpR5TDk62WzycUf6nRVUZLT9izRE,1093
 xplainable/gui/components/header.py,sha256=ZZgNpZLZsdN-latn8JgeHZT8lxX5J8x9mQoIT-raL1A,3018
 xplainable/gui/components/pipelines.py,sha256=fPXF3PFA0MOCY5UHuWURekuu57qPZDpL8RfNghB8TdI,8784
 xplainable/gui/components/tables.py,sha256=J-U6U8pi0Z7yqsGlEwrotCiARFpBLLDLT_Odkh33Odk,2848
 xplainable/gui/screens/__init__.py,sha256=yGoWdNrkJjVQIEHMYlFcktabTrFqCctJN0AKYyQ3St8,100
-xplainable/gui/screens/classifier.py,sha256=KpG4xSyJzB_O-fnDHQcbNCMoRgxZKfCDlx0rLc_Gj2s,24051
+xplainable/gui/screens/classifier.py,sha256=CaGtSTy1Sxk47cPlZlBCPgTTHoUUjyLwQAaNWH_f5l8,23982
 xplainable/gui/screens/evaluate.py,sha256=2n265ZTC8VyScv2PhWEPzVzuCqYwIJfyi7CGzCf21PA,38580
 xplainable/gui/screens/loader.py,sha256=47GNIuLy4HQkjrexAoWYBSef5xOLEp5RPihrrqezMcs,14819
 xplainable/gui/screens/preprocessor.py,sha256=aH7ur1WgsbhgaJKU9CY_qtj6EIVtq7t4qjJcVCB-we8,39855
-xplainable/gui/screens/regressor.py,sha256=OoIdzCQiAufDUVbXRy5YplabFXUkaoWUZ3sZLZ8fUDM,19156
-xplainable/gui/screens/save.py,sha256=xvMJMHjv9_ZgubkmT6gKK7MlJCj8kmwHtRO9n4OEdiY,20243
+xplainable/gui/screens/regressor.py,sha256=qJzaPo6A40x-4bFxSyh6HV15x__U3SL9Lt_NaPqrOHc,19494
+xplainable/gui/screens/save.py,sha256=bddxNDj1B6Cc1FMsTHDabLhSFOvSp-pI08uQ8bRXXoY,20280
 xplainable/gui/screens/scenario.py,sha256=xVQPIR_bUPUMKe_BVs7tBRH6JkEkhVaU-bqAVcO8Kh0,22064
 xplainable/metrics/__init__.py,sha256=Jk4ODFvbeCgS9ecmD1lftfaRNoL72q4Ek8VvWr5Nw6k,22
-xplainable/metrics/metrics.py,sha256=w2zTYvwz7eskT8d_D-UFvk_WxmRmooaM1NcfJ0sAlsY,4839
+xplainable/metrics/metrics.py,sha256=vtYw2RLrvtyhLStKfFcj18H8yPffetnbwPIUVwjavHQ,6074
 xplainable/preprocessing/__init__.py,sha256=X1oBxQgfGa97r9OKBeWdlOCwRH-IsBZeg4Y9kj0WtbM,27
 xplainable/preprocessing/pipeline.py,sha256=7Nhmiu5icIkWKqaGPA7Xmle93mzBsGUNlZGXhf-VXYw,6628
 xplainable/preprocessing/transformers/__init__.py,sha256=-8ld9w7w-QAjp_gMcYtlWS6gzrIiYW1xFmrubj-Ik_8,94
 xplainable/preprocessing/transformers/base.py,sha256=gatruZkPBSPxUDy96Dkv3YoFhfluusOFWOkE6hslsak,3518
 xplainable/preprocessing/transformers/categorical.py,sha256=TYrPdvmw-zcPnX2vH7IW1IkjrkSfZrtVWaHd7a9lZ94,19239
 xplainable/preprocessing/transformers/dataset.py,sha256=01l_QG6aqZJ1Xdtibv4T_9rsdlpzVIsmgfrRK2gBTIo,32659
 xplainable/preprocessing/transformers/mixed.py,sha256=dCdW8gx0go4ObpP9tXGTBGyfC8TvkZXBZP_VxFGhLkg,3201
@@ -59,12 +59,12 @@
 xplainable/utils/loaders.py,sha256=NKZbfS2O1zkU52myW99XH1srykAdfPBlcNQ_57yp7P8,2111
 xplainable/utils/numba_funcs.py,sha256=rwN9IoIrQ2HUoitojFGufGok7t6KNSLfgm0zrKgAoHg,1158
 xplainable/utils/svgs.py,sha256=Eond6CE1OPEW-D3W46NeKhD6Thr7Y4BQ9XsoRB30syg,4906
 xplainable/utils/xwidgets.py,sha256=0nC_Godb5ouTbQobAqTzFjeWQwSVTxTe5h8GT7NIoYQ,9759
 xplainable/visualisation/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 xplainable/visualisation/explain.py,sha256=Yt8TU2g0PY9eVH8m4bU2aAX4ZzpUA_-E_zH5nXu8JQ0,4380
 xplainable/visualisation/regression.py,sha256=bEaM3lLxoLCN51Gu7ysBuM9vkfgj3c7kMfk1oRa1y9Q,387
-xplainable-1.0.4.dist-info/LICENSE,sha256=ILBn-G3jdarm2w8oOrLmXeJNU3czuJvVhDLBASWdhM8,34522
-xplainable-1.0.4.dist-info/METADATA,sha256=QUXwmSRblHqZ_23suBbRikw3trCMcZEdblflM7AZyRM,48276
-xplainable-1.0.4.dist-info/WHEEL,sha256=2wepM1nk4DS4eFpYrW1TTqPcoGNfHhhO_i5m4cOimbo,92
-xplainable-1.0.4.dist-info/top_level.txt,sha256=Z4T05qncKSpRpo2KT4IVp6ORS5aYxyD3W6IGQTxCFek,17
-xplainable-1.0.4.dist-info/RECORD,,
+xplainable-1.0.5.dist-info/LICENSE,sha256=ILBn-G3jdarm2w8oOrLmXeJNU3czuJvVhDLBASWdhM8,34522
+xplainable-1.0.5.dist-info/METADATA,sha256=kxTSphJsPS57OwGj-QOovltzjr1VL2JbcFVNPGzdzpM,50058
+xplainable-1.0.5.dist-info/WHEEL,sha256=2wepM1nk4DS4eFpYrW1TTqPcoGNfHhhO_i5m4cOimbo,92
+xplainable-1.0.5.dist-info/top_level.txt,sha256=Z4T05qncKSpRpo2KT4IVp6ORS5aYxyD3W6IGQTxCFek,17
+xplainable-1.0.5.dist-info/RECORD,,
```

